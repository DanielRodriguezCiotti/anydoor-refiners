{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.anydoor_refiners.attention import CrossAttentionBlock2d\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "device = 'cuda:0'\n",
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention = CrossAttentionBlock2d(\n",
    "    channels=1280,\n",
    "    context_embedding_dim=1024,\n",
    "    context_key=\"dinov2_object_embedding\",\n",
    "    num_attention_heads=5,\n",
    "    num_attention_layers=1,\n",
    "    num_groups=32,\n",
    "    use_bias=False,\n",
    "    use_linear_projection=True,\n",
    "    use_attention_tv_loss=True,\n",
    "    device=device,\n",
    "    dtype=dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros((1, 1, 512, 512), device=device, dtype=dtype)\n",
    "box_x = (100, 200)\n",
    "box_y = (100, 200)\n",
    "mask[:, :, box_x[0]:box_x[1], box_y[0]:box_y[1]] = 1\n",
    "latents = torch.randn(1, 1280, 16, 16, device=device, dtype=dtype)\n",
    "\n",
    "embedding = torch.randn(1, 257, 1024, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cross_attention.set_context(\"atv_loss\", {\"value\": torch.tensor(0.0, device=device, dtype=dtype)})\n",
    "cross_attention.set_context(\"mask\", {\"mask\": mask})\n",
    "cross_attention.set_context(\"cross_attention_block\", {\"dinov2_object_embedding\":embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "I'm in\n",
      "torch.Size([5, 256, 256])\n",
      "257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/code/anydoor-refiners/.venv/lib/python3.11/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = cross_attention(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00018934524268843234"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_attention.use_context(\"atv_loss\")[\"value\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RES) CrossAttentionBlock2d(channels=1280, context_embedding_dim=1024, num_attention_heads=5, use_bias=False, context_key=dinov2_object_embedding, use_attention_tv_loss=True, use_linear_projection=True)\n",
       "    ├── (CHAIN) #1\n",
       "    │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float16)\n",
       "    │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   └── Flatten(start_dim=2)\n",
       "    │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   ├── Lambda(<lambda>(x))\n",
       "    │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float16)\n",
       "    ├── (CHAIN) #2\n",
       "    │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │       ├── (RES) Residual() #1\n",
       "    │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float16)\n",
       "    │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=5, inner_dim=1280, use_bias=False, is_optimized=False)\n",
       "    │       │       ├── (PAR)\n",
       "    │       │       │   ├── Identity() (x3)\n",
       "    │       │       │   └── UseContext(context=mask, key=mask)\n",
       "    │       │       ├── (DISTR)\n",
       "    │       │       │   ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float16) (x3)\n",
       "    │       │       │   └── Identity()\n",
       "    │       │       ├── XformersScaledDotProductAttention(head_dimension=256, use_attention_tv_loss=True, num_heads=5)\n",
       "    │       │       └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float16)\n",
       "    │       ├── (RES) Residual() #2\n",
       "    │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float16)\n",
       "    │       │   ├── (PAR)\n",
       "    │       │   │   ├── Identity()\n",
       "    │       │   │   └── UseContext(context=cross_attention_block, key=dinov2_object_embedding) (x2)\n",
       "    │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False)\n",
       "    │       │       ├── (DISTR)\n",
       "    │       │       │   ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float16) #1\n",
       "    │       │       │   └── Linear(in_features=1024, out_features=1280, device=cuda:0, dtype=float16) (x2) #2\n",
       "    │       │       ├── XformersScaledDotProductAttention(head_dimension=256, num_heads=5)\n",
       "    │       │       └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float16)\n",
       "    │       └── (RES) Residual() #3\n",
       "    │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float16)\n",
       "    │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float16) #1\n",
       "    │           ├── GLU()\n",
       "    │           │   └── GeLU()\n",
       "    │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float16) #2\n",
       "    └── (CHAIN) #3\n",
       "        ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float16)\n",
       "        ├── Lambda(<lambda>(x))\n",
       "        ├── Transpose(dim0=1, dim1=2)\n",
       "        ├── (PAR)\n",
       "        │   ├── Identity()\n",
       "        │   └── UseContext(context=flatten, key=sizes)\n",
       "        └── Unflatten(dim=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_attention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
