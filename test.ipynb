{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "import sys\n",
    "sys.path.append(\"./AnyDoor/\")\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "torch.set_num_threads(2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_dict_from_safetensors(path:str):\n",
    "    \"\"\" Load a state dict from a safetensors file \"\"\"\n",
    "    tensors = {}\n",
    "    with safe_open(path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set deterministic behavior\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.load(\"./tests/tensors/x.pt\",weights_only=True)\n",
    "initial_latents = torch.randn(1,4,64,64).to(device)\n",
    "object_embedding = torch.randn(1, 257, 1024).to(device)\n",
    "negative_object_embedding = torch.zeros(1, 257, 1024).to(device) #torch.load(\"./tests/tensors/negative_object_embedding.pt\",weights_only=True)\n",
    "control = [x.to(device) for x in torch.load(\"./tests/tensors/control_features.pt\",weights_only=True)]\n",
    "inference_steps = 10\n",
    "scale = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "ControlLDM: Running in eps-prediction mode\n",
      "DiffusionWrapper has 865.91 M params.\n",
      "Loaded model config from [./src/anydoor_original/configs/anydoor.yaml]\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from anydoor_original.cldm import model as cldm\n",
    "from cldm.ddim_hacked import DDIMSampler\n",
    "sampler = DDIMSampler(cldm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 32, 32), eta 0.0\n",
      "Running DDIM Sampling with 10 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  10%|█         | 1/10 [00:01<00:14,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(102.6943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  20%|██        | 2/10 [00:03<00:12,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(153.7481)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  30%|███       | 3/10 [00:04<00:10,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(214.7504)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  40%|████      | 4/10 [00:06<00:09,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(281.7013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  50%|█████     | 5/10 [00:07<00:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(349.3274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  60%|██████    | 6/10 [00:09<00:06,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(412.2058)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  70%|███████   | 7/10 [00:11<00:05,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(465.8795)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  80%|████████  | 8/10 [00:13<00:03,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(507.6265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  90%|█████████ | 9/10 [00:14<00:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(536.7265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 10/10 [00:16<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(536.9559)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mocked_control_image = torch.zeros(1, 4, 32, 32)\n",
    "    cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [object_embedding],\n",
    "    }\n",
    "    un_cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [negative_object_embedding],\n",
    "    }\n",
    "\n",
    "    samples, intermediates = sampler.sample(\n",
    "        S=inference_steps,\n",
    "        batch_size=1,\n",
    "        shape=(4, 32, 32),\n",
    "        conditioning=cond,\n",
    "        x_T=initial_latents.clone(),\n",
    "        verbose=False,\n",
    "        unconditional_guidance_scale=scale,\n",
    "        unconditional_conditioning=un_cond,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anydoor_refiners.model import AnyDoor,solver_params\n",
    "from anydoor_refiners.unet import UNet\n",
    "from refiners.foundationals.latent_diffusion.solvers import DDIM\n",
    "from tests.mocks import DINOv2EncoderMock,ControlNetMock,AnydoorAutoencoderMock\n",
    "\n",
    "unet = UNet(4).to(device)\n",
    "\n",
    "refiners_model = AnyDoor(\n",
    "    unet=unet,\n",
    "    lda=AnydoorAutoencoderMock(),\n",
    "    object_encoder=DINOv2EncoderMock(object_embedding,negative_object_embedding),\n",
    "    control_model=ControlNetMock(control),\n",
    "    solver=DDIM(inference_steps,params=solver_params)\n",
    ")\n",
    "# refiners_model.unet.load_state_dict(weights_refiners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from utils.weight_mapper import get_converted_state_dict\n",
    "\n",
    "with open(\"./tests/weights_mapping/unet.json\", \"r\") as f:\n",
    "    weight_mapping = json.load(f)\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=sampler.model.model.diffusion_model.state_dict(),\n",
    "    target_state_dict=refiners_model.unet.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "refiners_model.unet.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:07,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(102.6943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:06,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(153.7481)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:02<00:05,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(214.7505)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:03<00:04,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(281.7013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:03<00:03,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(349.3275)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:04<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(412.2059)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:05<00:02,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(465.8796)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:06<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(507.6266)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:06<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(536.7266)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(536.9562)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    y = initial_latents.clone()\n",
    "    for s in tqdm(refiners_model.steps):\n",
    "        y = refiners_model.forward(y,step=s,control_background_image=torch.zeros(1),object_embedding=object_embedding,negative_object_embedding=negative_object_embedding)\n",
    "        print(torch.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0002), tensor(536.9562), tensor(536.9559))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(y-samples[-1]),torch.norm(y),torch.norm(samples[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Anydoor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_anydoor = get_state_dict_from_safetensors(\"./ckpt/unet.safetensors\")\n",
    "sampler.model.model.diffusion_model.load_state_dict(weights_anydoor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=sampler.model.model.diffusion_model.state_dict(),\n",
    "    target_state_dict=refiners_model.unet.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "refiners_model.unet.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 32, 32), eta 0.0\n",
      "Running DDIM Sampling with 10 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  10%|█         | 1/10 [00:02<00:22,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.4161)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  20%|██        | 2/10 [00:03<00:15,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.9417)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  30%|███       | 3/10 [00:05<00:11,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.8006)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  40%|████      | 4/10 [00:07<00:11,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75.2370)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  50%|█████     | 5/10 [00:11<00:12,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77.0635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  60%|██████    | 6/10 [00:13<00:09,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77.3051)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  70%|███████   | 7/10 [00:15<00:06,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(76.4554)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  80%|████████  | 8/10 [00:17<00:04,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(74.5179)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:  90%|█████████ | 9/10 [00:19<00:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.9801)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 10/10 [00:21<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.8353)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mocked_control_image = torch.zeros(1, 4, 32, 32)\n",
    "    cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [object_embedding],\n",
    "    }\n",
    "    un_cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [negative_object_embedding],\n",
    "    }\n",
    "\n",
    "    samples, intermediates = sampler.sample(\n",
    "        S=inference_steps,\n",
    "        batch_size=1,\n",
    "        shape=(4, 32, 32),\n",
    "        conditioning=cond,\n",
    "        x_T=initial_latents.clone(),\n",
    "        verbose=False,\n",
    "        unconditional_guidance_scale=scale,\n",
    "        unconditional_conditioning=un_cond,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:15,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.4241)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:09,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.7671)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:07,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:07,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(74.3268)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:05<00:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75.4029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:06<00:04,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75.3962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(74.2556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:09<00:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.1551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:10<00:01,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67.1968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(66.6866)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    y = initial_latents.clone()\n",
    "    for s in tqdm(refiners_model.steps):\n",
    "        y = refiners_model.forward(y,step=s,control_background_image=torch.zeros(1),object_embedding=object_embedding,negative_object_embedding=negative_object_embedding)\n",
    "        print(torch.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(16.2772), tensor(66.6866), tensor(69.8353))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(y-samples[-1]),torch.norm(y),torch.norm(samples[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.weight_mapper import get_converted_state_dict\n",
    "from anydoor_refiners.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 4, 64, 64).to(device) \n",
    "timestep = torch.full((1,), 960, dtype=torch.long).to(device)\n",
    "object_embedding = torch.randn(1, 257, 1024).to(device)\n",
    "negative_object_embedding = torch.randn(1, 257, 1024).to(device) \n",
    "control = [x.to(device) for x in torch.load(\"./tests/tensors/control_features_real_size.pt\",weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "ControlLDM: Running in eps-prediction mode\n",
      "DiffusionWrapper has 865.91 M params.\n",
      "Loaded model config from [./src/anydoor_original/configs/anydoor.yaml]\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from anydoor_original.cldm import model as cldm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cldm.to(device)\n",
    "True # Just to avoid printing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [object_embedding],\n",
    "    }\n",
    "    y1 = cldm.apply_model(\n",
    "        x_noisy = x, \n",
    "        t = timestep, \n",
    "        cond = cond,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unet = UNet(4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"./tests/weights_mapping/unet.json\", \"r\") as f:\n",
    "    weight_mapping = json.load(f)\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=cldm.model.diffusion_model.state_dict(),\n",
    "    target_state_dict=unet.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "unet.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    unet.set_control_residuals(control)\n",
    "    unet.set_timestep(timestep)\n",
    "    unet.set_dinov2_object_embedding(object_embedding)\n",
    "    y2 = unet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(y1-y2),torch.norm(y1),torch.norm(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_weights = get_state_dict_from_safetensors(\"./ckpt/unet.safetensors\")\n",
    "cldm.model.diffusion_model.load_state_dict(unet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=cldm.model.diffusion_model.state_dict(),\n",
    "    target_state_dict=unet.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "unet.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [object_embedding],\n",
    "    }\n",
    "    y1_bis = cldm.apply_model(\n",
    "        x_noisy = x, \n",
    "        t = timestep, \n",
    "        cond = cond,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    unet.set_control_residuals(control)\n",
    "    unet.set_timestep(timestep)\n",
    "    unet.set_dinov2_object_embedding(object_embedding)\n",
    "    y2_bis = unet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(129.5021), tensor(129.5021))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(y1_bis-y2_bis),torch.norm(y1_bis),torch.norm(y2_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CHAIN) UNet(in_channels=4)\n",
       "    ├── (PASS) TimestepEncoder()\n",
       "    │   ├── UseContext(context=diffusion, key=timestep)\n",
       "    │   ├── (CHAIN) RangeEncoder(sinusoidal_embedding_dim=320, embedding_dim=1280)\n",
       "    │   │   ├── Lambda(compute_sinusoidal_embedding(x: jaxtyping.Int[Tensor, '*batch 1']) -> jaxtyping.Float[Tensor, '*batch 1 embedding_dim'])\n",
       "    │   │   ├── Converter(set_device=False)\n",
       "    │   │   ├── Linear(in_features=320, out_features=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   ├── SiLU()\n",
       "    │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   └── SetContext(context=range_adapter, key=timestep_embedding)\n",
       "    ├── (CHAIN) DownBlocks(in_channels=4)\n",
       "    │   ├── (CHAIN) #1\n",
       "    │   │   ├── Conv2d(in_channels=4, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=0)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=320, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=1)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #3\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=320, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=2)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #4\n",
       "    │   │   ├── (CHAIN) Downsample(channels=320, scale_factor=2, padding=1)\n",
       "    │   │   │   ├── SetContext(context=sampling, key=shapes)\n",
       "    │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=3)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #5\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=320, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=320, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=320, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=4)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #6\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=640, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=5)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #7\n",
       "    │   │   ├── (CHAIN) Downsample(channels=640, scale_factor=2, padding=1)\n",
       "    │   │   │   ├── SetContext(context=sampling, key=shapes)\n",
       "    │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=6)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #8\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=640, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=640, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=640, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=7)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #9\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=8)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #10\n",
       "    │   │   ├── (CHAIN) Downsample(channels=1280, scale_factor=2, padding=1)\n",
       "    │   │   │   ├── SetContext(context=sampling, key=shapes)\n",
       "    │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=9)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #11\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=10)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   └── (CHAIN) #12\n",
       "    │       ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280)\n",
       "    │       │   ├── (CHAIN)\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │   ├── SiLU() #1\n",
       "    │       │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │       │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   │   │   └── (CHAIN)\n",
       "    │       │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │       │   │   │       ├── SiLU()\n",
       "    │       │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │       │   │   ├── SiLU() #2\n",
       "    │       │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   └── Identity()\n",
       "    │       └── (PASS) ResidualAccumulator(n=11)\n",
       "    │           ├── (RES) Residual()\n",
       "    │           │   └── UseContext(context=unet, key=residuals)\n",
       "    │           └── SetContext(context=unet, key=residuals)\n",
       "    ├── (SUM)\n",
       "    │   ├── UseContext(context=unet, key=residuals)\n",
       "    │   └── (CHAIN) MiddleBlock()\n",
       "    │       ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280) #1\n",
       "    │       │   ├── (CHAIN)\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │   ├── SiLU() #1\n",
       "    │       │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │       │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   │   │   └── (CHAIN)\n",
       "    │       │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │       │   │   │       ├── SiLU()\n",
       "    │       │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │       │   │   ├── SiLU() #2\n",
       "    │       │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   └── Identity()\n",
       "    │       ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │       │   ├── (CHAIN) #1\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │       │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │       │   │   │   └── Flatten(start_dim=2)\n",
       "    │       │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │       │   │   ├── Lambda(<lambda>(x))\n",
       "    │       │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   ├── (CHAIN) #2\n",
       "    │       │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │       │   │       ├── (RES) Residual() #1\n",
       "    │       │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │       │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │       │   │       ├── (RES) Residual() #2\n",
       "    │       │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │       │   │       │   ├── (PAR) ...\n",
       "    │       │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │       │   │       └── (RES) Residual() #3\n",
       "    │       │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │       │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │           ├── GLU() ...\n",
       "    │       │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │       │   └── (CHAIN) #3\n",
       "    │       │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │       ├── Lambda(<lambda>(x))\n",
       "    │       │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │       │       ├── (PAR)\n",
       "    │       │       │   ├── Identity()\n",
       "    │       │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │       │       └── Unflatten(dim=2)\n",
       "    │       └── (SUM) ResidualBlock(in_channels=1280, out_channels=1280) #2\n",
       "    │           ├── (CHAIN)\n",
       "    │           │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │           │   ├── SiLU() #1\n",
       "    │           │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │           │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │           │   │   └── (CHAIN)\n",
       "    │           │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │           │   │       ├── SiLU()\n",
       "    │           │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │           │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │           │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │           │   ├── SiLU() #2\n",
       "    │           │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │           └── Identity()\n",
       "    ├── (CHAIN) UpBlocks()\n",
       "    │   ├── (CHAIN) #1\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-2)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── (RES) Residual()\n",
       "    │   │   │       │   └── UseContext(context=control, key=residuals)\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   └── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │       ├── (CHAIN)\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │   ├── SiLU() #1\n",
       "    │   │       │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │       │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       │   │   └── (CHAIN)\n",
       "    │   │       │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │       │   │       ├── SiLU()\n",
       "    │   │       │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       │   ├── SiLU() #2\n",
       "    │   │       │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #2\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-3)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   └── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │       ├── (CHAIN)\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │   ├── SiLU() #1\n",
       "    │   │       │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │       │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       │   │   └── (CHAIN)\n",
       "    │   │       │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │       │   │       ├── SiLU()\n",
       "    │   │       │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       │   ├── SiLU() #2\n",
       "    │   │       │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #3\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-4)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (CHAIN) Upsample(channels=1280)\n",
       "    │   │       ├── (PAR)\n",
       "    │   │       │   ├── Identity()\n",
       "    │   │       │   └── UseContext(context=sampling, key=shapes)\n",
       "    │   │       ├── Interpolate()\n",
       "    │   │       └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #4\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-5)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #5\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-6)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #6\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-7)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1920, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1920, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1920, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=1920, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (CHAIN) Upsample(channels=1280)\n",
       "    │   │       ├── (PAR)\n",
       "    │   │       │   ├── Identity()\n",
       "    │   │       │   └── UseContext(context=sampling, key=shapes)\n",
       "    │   │       ├── Interpolate()\n",
       "    │   │       └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #7\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-8)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1920, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1920, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1920, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=1920, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #8\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-9)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1280, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1280, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=1280, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #9\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-10)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=960, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=960, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=960, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=960, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (CHAIN) Upsample(channels=640)\n",
       "    │   │       ├── (PAR)\n",
       "    │   │       │   ├── Identity()\n",
       "    │   │       │   └── UseContext(context=sampling, key=shapes)\n",
       "    │   │       ├── Interpolate()\n",
       "    │   │       └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #10\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-11)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=960, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=960, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=960, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=960, out_channels=320, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #11\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-12)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=640, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=640, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=640, out_channels=320, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   └── (CHAIN) #12\n",
       "    │       ├── (CHAIN) ResidualControlledConcatenator(n=-13)\n",
       "    │       │   └── (CAT)\n",
       "    │       │       ├── Identity()\n",
       "    │       │       └── (SUM)\n",
       "    │       │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │       │           └── UseContext(context=control, key=residuals) #2\n",
       "    │       ├── (SUM) ResidualBlock(in_channels=640, out_channels=320)\n",
       "    │       │   ├── (CHAIN)\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │   ├── SiLU() #1\n",
       "    │       │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │       │   │   │   ├── Conv2d(in_channels=640, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   │   │   └── (CHAIN)\n",
       "    │       │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │       │   │   │       ├── SiLU()\n",
       "    │       │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │       │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │       │   │   ├── SiLU() #2\n",
       "    │       │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   └── Conv2d(in_channels=640, out_channels=320, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       └── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │           ├── (CHAIN) #1\n",
       "    │           │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │           │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │           │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │           │   │   └── Flatten(start_dim=2)\n",
       "    │           │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │           │   ├── Lambda(<lambda>(x))\n",
       "    │           │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │           ├── (CHAIN) #2\n",
       "    │           │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │           │       ├── (RES) Residual() #1\n",
       "    │           │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │           │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │           │       ├── (RES) Residual() #2\n",
       "    │           │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │           │       │   ├── (PAR) ...\n",
       "    │           │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │           │       └── (RES) Residual() #3\n",
       "    │           │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │           │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │           │           ├── GLU() ...\n",
       "    │           │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │           └── (CHAIN) #3\n",
       "    │               ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │               ├── Lambda(<lambda>(x))\n",
       "    │               ├── Transpose(dim0=1, dim1=2)\n",
       "    │               ├── (PAR)\n",
       "    │               │   ├── Identity()\n",
       "    │               │   └── UseContext(context=flatten, key=sizes)\n",
       "    │               └── Unflatten(dim=2)\n",
       "    └── (CHAIN)\n",
       "        ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32)\n",
       "        ├── SiLU()\n",
       "        └── Conv2d(in_channels=320, out_channels=4, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpatialTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.weight_mapper import get_converted_state_dict\n",
    "from anydoor_refiners.attention import CrossAttentionBlock2d\n",
    "import refiners.fluxion.layers as fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnyDoor.ldm.modules.attention import SpatialTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n"
     ]
    }
   ],
   "source": [
    "# Define model configuration parameters with descriptive names\n",
    "input_channels = 320  # Number of input channels for the model\n",
    "num_heads = 5  # Number of attention heads\n",
    "head_dim = 64  # Dimension of each attention head\n",
    "num_layers = 1  # Depth of attention layers\n",
    "context_dim = 1024  # Dimension of the context embedding\n",
    "use_linear_projection = True  # Whether to use linear projection in attention\n",
    "\n",
    "# Initialize the SpatialTransformer model\n",
    "spatial_transformer = SpatialTransformer(\n",
    "    in_channels=input_channels,\n",
    "    n_heads=num_heads,\n",
    "    d_head=head_dim,\n",
    "    depth=num_layers,\n",
    "    context_dim=context_dim,\n",
    "    use_linear=use_linear_projection,\n",
    "    use_checkpoint=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the CrossAttentionBlock2d model\n",
    "cross_attention_block = CrossAttentionBlock2d(\n",
    "    channels=input_channels,\n",
    "    context_embedding_dim=context_dim,\n",
    "    context_key=\"key\",  # Key to set the context in cross_attention_block\n",
    "    num_attention_heads=num_heads,\n",
    "    num_attention_layers=num_layers,\n",
    "    num_groups=32,  # Number of groups for grouped attention\n",
    "    use_bias=False,\n",
    "    use_linear_projection=use_linear_projection,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the source model's state dict to match the target model's structure\n",
    "with open(\"tests/weights_mapping/cross_attention_block_2d.json\", \"r\") as f:\n",
    "    weight_mapping = json.load(f)\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=spatial_transformer.state_dict(),\n",
    "    target_state_dict=cross_attention_block.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "cross_attention_block.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'),\n",
       " tensor(573.0254, device='cuda:0'),\n",
       " tensor(573.0254, device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "context_dim = 1024  # Must match the model's context dimension configuration\n",
    "input_tensor = torch.randn(1, input_channels, 32, 32).to(device)  # Example input tensor\n",
    "context_tensor = torch.randn(1, 1, context_dim).to(device)  # Example context tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Set the context for the CrossAttentionBlock2d model\n",
    "    cross_attention_block.set_context(  # noqa: F821\n",
    "        \"cross_attention_block\", {\"key\": context_tensor}\n",
    "    )\n",
    "    # Forward pass through both models\n",
    "    y_source = spatial_transformer.forward(input_tensor, context=context_tensor)\n",
    "    y_target = cross_attention_block.forward(input_tensor)  # noqa: F821\n",
    "    \n",
    "torch.norm(y_target-y_source),torch.norm(y_target),torch.norm(y_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spatial_transformer_weights = get_state_dict_from_safetensors(\"./ckpt/spatial_transformer.safetensors\")\n",
    "spatial_transformer.load_state_dict(spatial_transformer_weights)\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=spatial_transformer.state_dict(),\n",
    "    target_state_dict=cross_attention_block.state_dict(),  # noqa: F821\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "cross_attention_block.load_state_dict(converted_state_dict)  # noqa: F821\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(207.9414, device='cuda:0'),\n",
       " tensor(540.9109, device='cuda:0'),\n",
       " tensor(529.5787, device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "context_dim = 1024  # Must match the model's context dimension configuration\n",
    "input_tensor = torch.randn(1, input_channels, 32, 32).to(device)  # Example input tensor\n",
    "context_tensor = torch.randn(1, 1, context_dim).to(device)  # Example context tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Set the context for the CrossAttentionBlock2d model\n",
    "    cross_attention_block.set_context(  # noqa: F821\n",
    "        \"cross_attention_block\", {\"key\": context_tensor}\n",
    "    )\n",
    "    # Forward pass through both models\n",
    "    y_target = cross_attention_block.forward(input_tensor)  # noqa: F821\n",
    "    y_source = spatial_transformer.forward(input_tensor, context=context_tensor)\n",
    "    \n",
    "torch.norm(y_target-y_source),torch.norm(y_target),torch.norm(y_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_block_keys = [\n",
    "    k for k in spatial_transformer_weights.keys() if \"transformer_blocks.0.\" in k\n",
    "]\n",
    "transformer_block_weights = {\n",
    "    k.replace(\"transformer_blocks.0.\",\"\"): spatial_transformer_weights[k] for k in transformer_block_keys\n",
    "}\n",
    "save_file(transformer_block_weights,\"./ckpt/transformer_block.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_projection_weight_keys = [\n",
    "    'norm.bias', 'norm.weight', 'proj_in.bias', 'proj_in.weight'\n",
    "]\n",
    "input_projection_weights = {\n",
    "    key: spatial_transformer.state_dict()[key]\n",
    "    for key in input_projection_weight_keys\n",
    "}\n",
    "save_file(input_projection_weights, \"./ckpt/input_projection.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_projection_weight_keys = [\n",
    "    'proj_out.bias', 'proj_out.weight'\n",
    "]\n",
    "output_projection_weights = {\n",
    "    key: spatial_transformer.state_dict()[key]\n",
    "    for key in output_projection_weight_keys\n",
    "}\n",
    "save_file(output_projection_weights, \"./ckpt/output_projection.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Projection\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import refiners.fluxion.layers as fl\n",
    "from torch import nn\n",
    "from utils.weight_mapper import get_converted_state_dict\n",
    "from einops import rearrange\n",
    "from refiners.fluxion.context import Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(num_groups=32, num_channels=320, eps=1e-6, affine=True)\n",
    "        self.proj_in = nn.Linear(320, 320)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = rearrange(x, \"b c h w -> b (h w) c\").contiguous()\n",
    "        x = self.proj_in(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class SmallModelRefiners(fl.Chain):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            fl.GroupNorm(\n",
    "                channels=320,\n",
    "                num_groups=32,\n",
    "                eps=1e-6\n",
    "            ),\n",
    "            fl.Flatten(start_dim=2, end_dim=-1),\n",
    "            fl.Transpose(1, 2),\n",
    "            fl.Lambda(lambda x: x.contiguous()),\n",
    "            fl.Linear(\n",
    "                in_features=320,\n",
    "                out_features=320,\n",
    "            ),\n",
    "        )\n",
    "    def init_context(self) -> Contexts:\n",
    "        return {\"flatten\": {\"sizes\": []}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "anydoor = SmallModel().to(device)\n",
    "refiners = SmallModelRefiners().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"GroupNorm\": \"norm\",\n",
    "    \"Linear\": \"proj_in\",\n",
    "}\n",
    "refiners_state_dict_converted = get_converted_state_dict(\n",
    "    source_state_dict=anydoor.state_dict(),\n",
    "    target_state_dict=refiners.state_dict(),\n",
    "    mapping=mapping,\n",
    ")\n",
    "refiners.load_state_dict(refiners_state_dict_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'),\n",
       " tensor(330.6661, device='cuda:0'),\n",
       " tensor(330.6661, device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "input_tensor = torch.randn(1, input_channels, 32, 32).to(device)  # Example input tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_projected_target = anydoor.forward(input_tensor) \n",
    "    y_projected_source = refiners.forward(input_tensor)\n",
    "    \n",
    "torch.norm(y_projected_target-y_projected_source),torch.norm(y_projected_target),torch.norm(y_projected_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weights = get_state_dict_from_safetensors(\"./ckpt/input_projection.safetensors\")\n",
    "anydoor.load_state_dict(weights)\n",
    "refiners_state_dict_converted = get_converted_state_dict(\n",
    "    source_state_dict=anydoor.state_dict(),\n",
    "    target_state_dict=refiners.state_dict(),\n",
    "    mapping=mapping,\n",
    ")\n",
    "refiners.load_state_dict(refiners_state_dict_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'),\n",
       " tensor(176.8964, device='cuda:0'),\n",
       " tensor(176.8964, device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "input_tensor = torch.randn(1, input_channels, 32, 32).to(device)  # Example input tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_projected_target = anydoor.forward(input_tensor) \n",
    "    y_projected_source = refiners.forward(input_tensor)\n",
    "    \n",
    "torch.norm(y_projected_target-y_projected_source),torch.norm(y_projected_target),torch.norm(y_projected_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransformerBlock\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.weight_mapper import get_converted_state_dict\n",
    "from anydoor_refiners.attention import CrossAttentionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AnyDoor.ldm.modules.attention import BasicTransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configuration parameters with descriptive names\n",
    "input_channels = 320  # Number of input channels for the model\n",
    "num_heads = 5  # Number of attention heads\n",
    "head_dim = 64  # Dimension of each attention head\n",
    "num_layers = 1  # Depth of attention layers\n",
    "context_dim = 1024  # Dimension of the context embedding\n",
    "use_linear_projection = True  # Whether to use linear projection in attention\n",
    "\n",
    "# Initialize the SpatialTransformer model\n",
    "anydoor = BasicTransformerBlock(\n",
    "    dim=input_channels,\n",
    "    n_heads=num_heads,\n",
    "    d_head=head_dim,\n",
    "    context_dim=context_dim,\n",
    "    disable_self_attn=False,\n",
    "    checkpoint=True).to(device)\n",
    "\n",
    "refiners = CrossAttentionBlock(\n",
    "    embedding_dim=input_channels,\n",
    "    context_embedding_dim=context_dim,\n",
    "    context_key=\"key\",\n",
    "    num_heads=num_heads,\n",
    "    use_bias=False).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Residual_1.SelfAttention.Linear\": \"attn1.to_out.0\",\n",
    "    \"Residual_2.Attention.Linear\": \"attn2.to_out.0\",\n",
    "    \"Residual_1.LayerNorm\": \"norm1\",\n",
    "    \"Residual_2.LayerNorm\": \"norm2\",\n",
    "    \"Residual_3.LayerNorm\": \"norm3\",\n",
    "    \"Residual_1.SelfAttention.Distribute.Linear_1\": \"attn1.to_q\",\n",
    "    \"Residual_1.SelfAttention.Distribute.Linear_2\": \"attn1.to_k\",\n",
    "    \"Residual_1.SelfAttention.Distribute.Linear_3\": \"attn1.to_v\",\n",
    "    \"Residual_2.Attention.Distribute.Linear_1\": \"attn2.to_q\",\n",
    "    \"Residual_2.Attention.Distribute.Linear_2\": \"attn2.to_k\",\n",
    "    \"Residual_2.Attention.Distribute.Linear_3\": \"attn2.to_v\",\n",
    "    \"Residual_3.Linear_1\": \"ff.net.0.proj\",\n",
    "    \"Residual_3.Linear_2\": \"ff.net.2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=anydoor.state_dict(),\n",
    "    target_state_dict=refiners.state_dict(),\n",
    "    mapping=mapping,\n",
    ")\n",
    "refiners.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.9120e-06, device='cuda:0'),\n",
       " tensor(27.1595, device='cuda:0'),\n",
       " tensor(27.1595, device='cuda:0'))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "context_dim = 1024  # Must match the model's context dimension configuration\n",
    "input_tensor = torch.randn(1, 2, input_channels).to(device)  # Example input tensor\n",
    "context_tensor = torch.randn(1, 1, context_dim).to(device)  # Example context tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Set the context for the CrossAttentionBlock2d model\n",
    "    refiners.set_context(  # noqa: F821\n",
    "        \"cross_attention_block\", {\"key\": context_tensor}\n",
    "    )\n",
    "    # Forward pass through both models\n",
    "    y_target = refiners.forward(input_tensor)  # noqa: F821\n",
    "    y_source = anydoor.forward(input_tensor, context=context_tensor)\n",
    "    \n",
    "torch.norm(y_target-y_source),torch.norm(y_target),torch.norm(y_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weights = get_state_dict_from_safetensors(\"./ckpt/transformer_block.safetensors\")\n",
    "anydoor.load_state_dict(weights)\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=anydoor.state_dict(),\n",
    "    target_state_dict=refiners.state_dict(),  # noqa: F821\n",
    "    mapping=mapping,\n",
    ")\n",
    "refiners.load_state_dict(converted_state_dict)  # noqa: F821\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'),\n",
       " tensor(1719.6464, device='cuda:0'),\n",
       " tensor(1719.6464, device='cuda:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "context_dim = 1024  # Must match the model's context dimension configuration\n",
    "input_tensor = torch.randn(1, 1, input_channels).to(device) * 100  # Example input tensor\n",
    "context_tensor = torch.randn(1, 1, context_dim).to(device)  # Example context tensor\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Set the context for the CrossAttentionBlock2d model\n",
    "    refiners.set_context(  # noqa: F821\n",
    "        \"cross_attention_block\", {\"key\": context_tensor}\n",
    "    )\n",
    "    # Forward pass through both models\n",
    "    y_target = refiners.forward(input_tensor)  # noqa: F821\n",
    "    y_source = anydoor.forward(input_tensor, context=context_tensor)\n",
    "    \n",
    "print(torch.allclose(y_target,y_source,rtol=1e-7,atol=1e-7))\n",
    "torch.norm(y_target-y_source),torch.norm(y_target),torch.norm(y_source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DerangedModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(num_groups=32, num_channels=320, eps=1e-6, affine=True)\n",
    "        self.proj_in = nn.Linear(320, 320)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.norm(x)\n",
    "        x = rearrange(x, \"b c h w -> b (h w) c\").contiguous()\n",
    "        x = self.proj_in(x)\n",
    "        return x\n",
    "\n",
    "model = DerangedModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input tensors\n",
    "input_channels = 320  # Must match the model's input channel configuration\n",
    "context_dim = 1024  # Must match the model's context dimension configuration\n",
    "input_tensor = torch.randn(1, 2, input_channels).to(device)   # Example input tensor\n",
    "context_tensor = torch.randn(1, 1, context_dim).to(device)  # Example context tensor\n",
    "\n",
    "input_tensor_2 = model(torch.randn( 1, input_channels, 32 , 32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 320]), torch.Size([1, 1024, 320]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape,input_tensor_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor(3.6385e-06, device='cuda:0') tensor(27.5168, device='cuda:0') tensor(27.5168, device='cuda:0')\n",
      "True\n",
      "tensor(0., device='cuda:0') tensor(387.2995, device='cuda:0') tensor(387.2995, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    # Set the context for the CrossAttentionBlock2d model\n",
    "    refiners.set_context(  # noqa: F821\n",
    "        \"cross_attention_block\", {\"key\": context_tensor.clone()}\n",
    "    )\n",
    "    # Forward pass through both models\n",
    "    y1 = refiners.forward(input_tensor)  # noqa: F821\n",
    "    y2 = anydoor.forward(input_tensor, context=context_tensor.clone())\n",
    "    \n",
    "    print(torch.allclose(y1,y2,rtol=1e-7,atol=1e-7)) # type: ignore\n",
    "    print(torch.norm(y1-y2),torch.norm(y1),torch.norm(y2))\n",
    "\n",
    "    # Set the context for the CrossAttentionBlock2d model\n",
    "    refiners.set_context(  # noqa: F821\n",
    "        \"cross_attention_block\", {\"key\": context_tensor.clone()}\n",
    "    )\n",
    "    # Forward pass through both models\n",
    "    y1_bis = refiners.forward(y_projected_target)  # noqa: F821\n",
    "    y2_bis = anydoor.forward(y_projected_target, context=context_tensor.clone())\n",
    "    \n",
    "    print(torch.allclose(y1_bis,y2_bis,rtol=1e-7,atol=1e-7))\n",
    "    print(torch.norm(y1_bis-y2_bis),torch.norm(y1_bis),torch.norm(y2_bis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refiners.conversion.model_converter import ModelConverter\n",
    "\n",
    "model_converter = ModelConverter(source_model=anydoor, target_model=refiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0 -> 1 - Models have the same number of basic layers. Finding matching shapes and layers...\n",
      "Stage 1 -> 2 - Shape of both models agree. Applying state_dict to target model. Comparing models...\n",
      "Models diverged between attn1.to_v and attn1.to_out.0, and between Residual_1.SelfAttention.Distribute.Linear_3 and Residual_1.SelfAttention.Linear, difference in norm: 9.048733045347035e-05\n",
      "Models do not agree. Try to increase the threshold or modify the models.\n",
      "Conversion failed at stage 3\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    refiners.set_context( \n",
    "        \"cross_attention_block\", {\"key\": context_tensor.clone()}\n",
    "    )\n",
    "    model_converter.run(source_args=(y_projected_source, context_tensor), target_args=(y_projected_source,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_projected_target.dtype, y_projected_source.dtype, torch.allclose(y_projected_target,y_projected_source,rtol=1e-12,atol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_projected_target.is_contiguous(), y_projected_source.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n"
     ]
    }
   ],
   "source": [
    "for weight in refiners.parameters():\n",
    "    print(weight.is_contiguous(), weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n",
      "True torch.float32\n"
     ]
    }
   ],
   "source": [
    "for weight in anydoor.parameters():\n",
    "    print(weight.is_contiguous(), weight.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import scaled_dot_product_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product_attention_non_optimized(\n",
    "    query: Float[Tensor, \"batch source_sequence_length dim\"],\n",
    "    key: Float[Tensor, \"batch target_sequence_length dim\"],\n",
    "    value: Float[Tensor, \"batch target_sequence_length dim\"],\n",
    "    is_causal: bool = False,\n",
    ") -> Float[Tensor, \"batch source_sequence_length dim\"]:\n",
    "    \"\"\"Non-optimized Scaled Dot Product Attention.\n",
    "\n",
    "    See [[arXiv:1706.03762] Attention Is All You Need (Equation 1)](https://arxiv.org/abs/1706.03762) for more details.\n",
    "    \"\"\"\n",
    "    if is_causal:\n",
    "        # TODO: implement causal attention\n",
    "        raise NotImplementedError(\n",
    "            \"Causal attention for `scaled_dot_product_attention_non_optimized` is not yet implemented\"\n",
    "        )\n",
    "\n",
    "    dim = query.shape[-1]\n",
    "    attention = query @ key.permute(0, 1, 3, 2)\n",
    "    attention = attention / math.sqrt(dim)\n",
    "    attention = torch.softmax(input=attention, dim=-1)\n",
    "    return attention @ value\n",
    "\n",
    "class ScaledDotProductAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads: int = 1,\n",
    "        is_causal: bool = False,\n",
    "        is_optimized: bool = True,\n",
    "        slice_size: int | None = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.is_causal = is_causal\n",
    "        self.is_optimized = is_optimized\n",
    "        self.slice_size = slice_size\n",
    "        self.dot_product = scaled_dot_product_attention_non_optimized\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        query: Float[Tensor, \"batch num_queries embedding_dim\"],\n",
    "        key: Float[Tensor, \"batch num_keys embedding_dim\"],\n",
    "        value: Float[Tensor, \"batch num_values embedding_dim\"],\n",
    "    ) -> Float[Tensor, \"batch num_queries embedding_dim\"]:\n",
    "\n",
    "        return self._process_attention(\n",
    "            query=query,\n",
    "            key=key,\n",
    "            value=value,\n",
    "        )\n",
    "\n",
    "\n",
    "    def _process_attention(\n",
    "        self,\n",
    "        query: Float[Tensor, \"batch num_queries embedding_dim\"],\n",
    "        key: Float[Tensor, \"batch num_keys embedding_dim\"],\n",
    "        value: Float[Tensor, \"batch num_values embedding_dim\"],\n",
    "    ) -> Float[Tensor, \"batch num_queries embedding_dim\"]:\n",
    "        return self._merge_multi_head(\n",
    "            x=self.dot_product(\n",
    "                query=self._split_to_multi_head(query),\n",
    "                key=self._split_to_multi_head(key),\n",
    "                value=self._split_to_multi_head(value),\n",
    "                is_causal=self.is_causal,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _split_to_multi_head(\n",
    "        self,\n",
    "        x: Float[Tensor, \"batch_size sequence_length embedding_dim\"],\n",
    "    ) -> Float[Tensor, \"batch_size num_heads sequence_length (embedding_dim//num_heads)\"]:\n",
    "        \"\"\"Split the input tensor into multiple heads along the embedding dimension.\n",
    "\n",
    "        See also `merge_multi_head`, which is the inverse operation.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            x.ndim == 3\n",
    "        ), f\"Expected input tensor with shape (batch_size sequence_length embedding_dim), got {x.shape}\"\n",
    "        assert (\n",
    "            x.shape[-1] % self.num_heads == 0\n",
    "        ), f\"Expected embedding_dim (x.shape[-1]={x.shape[-1]}) to be divisible by num_heads ({self.num_heads})\"\n",
    "\n",
    "        return x.reshape(x.shape[0], x.shape[1], self.num_heads, x.shape[-1] // self.num_heads).transpose(1, 2)\n",
    "\n",
    "    def _merge_multi_head(\n",
    "        self,\n",
    "        x: Float[Tensor, \"batch_size num_heads sequence_length heads_dim\"],\n",
    "    ) -> Float[Tensor, \"batch_size sequence_length heads_dim * num_heads\"]:\n",
    "        \"\"\"Merge the input tensor from multiple heads along the embedding dimension.\n",
    "\n",
    "        See also `split_to_multi_head`, which is the inverse operation.\n",
    "        \"\"\"\n",
    "        return x.transpose(1, 2).reshape(x.shape[0], x.shape[2], self.num_heads * x.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AnyDoorAttentionProduct(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, heads: int):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = 64 ** -0.5\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        h = self.heads\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=h), (q, k, v))\n",
    "\n",
    "        with torch.autocast(enabled=False, device_type = 'cuda'):\n",
    "            q, k = q.float(), k.float()\n",
    "            sim = torch.einsum('b i d, b j d -> b i j', q, k) * self.scale\n",
    "        \n",
    "        del q, k\n",
    "\n",
    "        # attention, what we cannot get enough of\n",
    "        sim = sim.softmax(dim=-1)\n",
    "\n",
    "        out = torch.einsum('b i j, b j d -> b i d', sim, v)\n",
    "        out = rearrange(out, '(b h) n d -> b n (h d)', h=h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "refiners_attention = ScaledDotProductAttention(num_heads=5).to(device)\n",
    "anydoor_attention = AnyDoorAttentionProduct(heads=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'),\n",
       " tensor(23.2752, device='cuda:0'),\n",
       " tensor(23.2752, device='cuda:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input tensors\n",
    "dim = 320  \n",
    "q = torch.randn(1, 10, 320).to(device)  # Example input tensor\n",
    "k = torch.randn(1, 10, 320).to(device)  # Example input tensor\n",
    "v = torch.randn(1, 10, 320).to(device)  # Example input tensor\n",
    "\n",
    "anydoor_result = anydoor_attention(q, k, v)\n",
    "refiners_result = refiners_attention(q, k, v)\n",
    "\n",
    "torch.norm(anydoor_result-refiners_result),torch.norm(anydoor_result),torch.norm(refiners_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Projection\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_projection = nn.Linear(320,320)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_target = output_projection(y_target) \n",
    "    y_source = output_projection(y_source)\n",
    "\n",
    "torch.norm(y_target-y_source),torch.norm(y_target),torch.norm(y_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_state_dict_from_safetensors(\"./ckpt/output_projection.safetensors\")\n",
    "output_projection.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_projection = nn.Linear(320,320)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_target = output_projection(y_target) \n",
    "    y_source = output_projection(y_source)\n",
    "\n",
    "torch.norm(y_target-y_source),torch.norm(y_target),torch.norm(y_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "sys.path.append(\"./AnyDoor/\")\n",
    "from ldm.util import instantiate_from_config\n",
    "\n",
    "conf = OmegaConf.load(\"src/anydoor_original/configs/anydoor.yaml\")\n",
    "\n",
    "lda_anydoor = instantiate_from_config(conf.model.params.first_stage_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/grxhyczx135dcrhc7pzfhkxr0000gn/T/ipykernel_4580/2496509189.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lda_anydoor.load_state_dict(torch.load(\"ckpt/lda_anydoor.ckpt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_anydoor.load_state_dict(torch.load(\"ckpt/lda_anydoor.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anydoor_refiners.model import AnydoorAutoencoder\n",
    "\n",
    "lda_refiners = AnydoorAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_refiners = lda_refiners.load_from_safetensors(\"ckpt/anydoor_refiners_safetensors/lda.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83653863\n",
      "83653863\n"
     ]
    }
   ],
   "source": [
    "# Print nb of trainable parameters of the two models\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(lda_anydoor))\n",
    "print(count_parameters(lda_refiners))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    img = torch.randn(1,3,256,256)\n",
    "    y1 = lda_refiners.forward(img)\n",
    "    y2 = lda_anydoor.forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(207.3743)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(y1 - y2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refiners.conversion.model_converter import ModelConverter\n",
    "\n",
    "converter = ModelConverter(source_model=lda_anydoor,target_model=lda_refiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models do not have the same number of basic layers:\n",
      "  <class 'torch.nn.modules.conv.Conv2d'>: Source 72 - Target 64\n",
      "  <class 'torch.nn.modules.linear.Linear'>: Source 0 - Target 8\n",
      "Conversion failed at stage 1\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    img = torch.randn(1,3,256,256)\n",
    "    converter.run(source_args=(img,),target_args=(img,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ControlNet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils.weight_mapper import get_converted_state_dict\n",
    "from anydoor_refiners.controlnet import ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 4, 512, 512).to(device) ##torch.load(\"./tests/tensors/x.pt\",weights_only=True).to(device)\n",
    "# initial_latents = torch.randn(1,4,32,32).to(device)\n",
    "timestep = torch.full((1,), 1, dtype=torch.long).to(device)\n",
    "object_embedding = torch.randn(1, 257, 1024).to(device)#torch.load(\"./tests/tensors/object_embedding.pt\",weights_only=True).to(device)\n",
    "# negative_object_embedding = torch.randn(1, 257, 1024).to(device) #torch.load(\"./tests/tensors/negative_object_embedding.pt\",weights_only=True).to(device)\n",
    "# control = [x.to(device) for x in torch.load(\"./tests/tensors/control_features.pt\",weights_only=True)]\n",
    "# inference_steps = 10\n",
    "# scale = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module 'xformers'. Proceeding without it.\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from anydoor_original.control_net import model as controlnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.to(device)\n",
    "True # Just to avoid printing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    control = controlnet.forward(torch.zeros(1), x, timestep, object_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "controlnet_refiners = ControlNet(4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Layer 'input_blocks.0.0' not found in mapping.\n",
      "[Warning] Layer 'input_blocks.0.0' not found in mapping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"./tests/weights_mapping/control_net.json\", \"r\") as f:\n",
    "    weight_mapping = json.load(f)\n",
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=controlnet.state_dict(),\n",
    "    target_state_dict=controlnet_refiners.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "controlnet_refiners.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    controlnet_refiners.set_timestep(timestep)\n",
    "    controlnet_refiners.set_dinov2_object_embedding(object_embedding)\n",
    "    control2 = controlnet_refiners(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) torch.Size([1, 320, 64, 64]) torch.Size([1, 320, 64, 64])\n",
      "tensor(0.) torch.Size([1, 320, 64, 64]) torch.Size([1, 320, 64, 64])\n",
      "tensor(0.) torch.Size([1, 320, 64, 64]) torch.Size([1, 320, 64, 64])\n",
      "tensor(0.) torch.Size([1, 320, 32, 32]) torch.Size([1, 320, 32, 32])\n",
      "tensor(0.) torch.Size([1, 640, 32, 32]) torch.Size([1, 640, 32, 32])\n",
      "tensor(0.) torch.Size([1, 640, 32, 32]) torch.Size([1, 640, 32, 32])\n",
      "tensor(0.) torch.Size([1, 640, 16, 16]) torch.Size([1, 640, 16, 16])\n",
      "tensor(0.) torch.Size([1, 1280, 16, 16]) torch.Size([1, 1280, 16, 16])\n",
      "tensor(0.) torch.Size([1, 1280, 16, 16]) torch.Size([1, 1280, 16, 16])\n",
      "tensor(0.) torch.Size([1, 1280, 8, 8]) torch.Size([1, 1280, 8, 8])\n",
      "tensor(0.) torch.Size([1, 1280, 8, 8]) torch.Size([1, 1280, 8, 8])\n",
      "tensor(0.) torch.Size([1, 1280, 8, 8]) torch.Size([1, 1280, 8, 8])\n",
      "tensor(0.) torch.Size([1, 1280, 8, 8]) torch.Size([1, 1280, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for i,tensor in enumerate(control):\n",
    "    print(torch.norm(tensor-control2[i]), tensor.shape, control2[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save control tensors\n",
    "torch.save(control2, \"tests/tensors/control_features_real_size.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_state_dict_from_safetensors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m unet_weights \u001b[38;5;241m=\u001b[39m \u001b[43mget_state_dict_from_safetensors\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ckpt/unet.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      2\u001b[0m cldm\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdiffusion_model\u001b[38;5;241m.\u001b[39mload_state_dict(unet_weights)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_state_dict_from_safetensors' is not defined"
     ]
    }
   ],
   "source": [
    "unet_weights = get_state_dict_from_safetensors(\"./ckpt/unet.safetensors\")\n",
    "cldm.model.diffusion_model.load_state_dict(unet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "converted_state_dict = get_converted_state_dict(\n",
    "    source_state_dict=cldm.model.diffusion_model.state_dict(),\n",
    "    target_state_dict=unet.state_dict(),\n",
    "    mapping=weight_mapping,\n",
    ")\n",
    "unet.load_state_dict(converted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cond = {\n",
    "        \"c_concat\": control, ## Not used\n",
    "        \"c_crossattn\": [object_embedding],\n",
    "    }\n",
    "    y1_bis = cldm.apply_model(\n",
    "        x_noisy = x, \n",
    "        t = timestep, \n",
    "        cond = cond,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    unet.set_control_residuals(control)\n",
    "    unet.set_timestep(timestep)\n",
    "    unet.set_dinov2_object_embedding(object_embedding)\n",
    "    y2_bis = unet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(65.7131), tensor(65.7131))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.norm(y1_bis-y2_bis),torch.norm(y1_bis),torch.norm(y2_bis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CHAIN) UNet(in_channels=4)\n",
       "    ├── (PASS) TimestepEncoder()\n",
       "    │   ├── UseContext(context=diffusion, key=timestep)\n",
       "    │   ├── (CHAIN) RangeEncoder(sinusoidal_embedding_dim=320, embedding_dim=1280)\n",
       "    │   │   ├── Lambda(compute_sinusoidal_embedding(x: jaxtyping.Int[Tensor, '*batch 1']) -> jaxtyping.Float[Tensor, '*batch 1 embedding_dim'])\n",
       "    │   │   ├── Converter(set_device=False)\n",
       "    │   │   ├── Linear(in_features=320, out_features=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   ├── SiLU()\n",
       "    │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   └── SetContext(context=range_adapter, key=timestep_embedding)\n",
       "    ├── (CHAIN) DownBlocks(in_channels=4)\n",
       "    │   ├── (CHAIN) #1\n",
       "    │   │   ├── Conv2d(in_channels=4, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=0)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=320, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=1)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #3\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=320, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=2)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #4\n",
       "    │   │   ├── (CHAIN) Downsample(channels=320, scale_factor=2, padding=1)\n",
       "    │   │   │   ├── SetContext(context=sampling, key=shapes)\n",
       "    │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=3)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #5\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=320, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=320, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=320, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=4)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #6\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=640, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=5)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #7\n",
       "    │   │   ├── (CHAIN) Downsample(channels=640, scale_factor=2, padding=1)\n",
       "    │   │   │   ├── SetContext(context=sampling, key=shapes)\n",
       "    │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=6)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #8\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=640, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=640, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=640, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=7)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #9\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=8)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #10\n",
       "    │   │   ├── (CHAIN) Downsample(channels=1280, scale_factor=2, padding=1)\n",
       "    │   │   │   ├── SetContext(context=sampling, key=shapes)\n",
       "    │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=9)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   ├── (CHAIN) #11\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Identity()\n",
       "    │   │   └── (PASS) ResidualAccumulator(n=10)\n",
       "    │   │       ├── (RES) Residual()\n",
       "    │   │       │   └── UseContext(context=unet, key=residuals)\n",
       "    │   │       └── SetContext(context=unet, key=residuals)\n",
       "    │   └── (CHAIN) #12\n",
       "    │       ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280)\n",
       "    │       │   ├── (CHAIN)\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │   ├── SiLU() #1\n",
       "    │       │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │       │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   │   │   └── (CHAIN)\n",
       "    │       │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │       │   │   │       ├── SiLU()\n",
       "    │       │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │       │   │   ├── SiLU() #2\n",
       "    │       │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   └── Identity()\n",
       "    │       └── (PASS) ResidualAccumulator(n=11)\n",
       "    │           ├── (RES) Residual()\n",
       "    │           │   └── UseContext(context=unet, key=residuals)\n",
       "    │           └── SetContext(context=unet, key=residuals)\n",
       "    ├── (SUM)\n",
       "    │   ├── UseContext(context=unet, key=residuals)\n",
       "    │   └── (CHAIN) MiddleBlock()\n",
       "    │       ├── (SUM) ResidualBlock(in_channels=1280, out_channels=1280) #1\n",
       "    │       │   ├── (CHAIN)\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │   ├── SiLU() #1\n",
       "    │       │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │       │   │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   │   │   └── (CHAIN)\n",
       "    │       │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │       │   │   │       ├── SiLU()\n",
       "    │       │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │       │   │   ├── SiLU() #2\n",
       "    │       │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   └── Identity()\n",
       "    │       ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │       │   ├── (CHAIN) #1\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │       │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │       │   │   │   └── Flatten(start_dim=2)\n",
       "    │       │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │       │   │   ├── Lambda(<lambda>(x))\n",
       "    │       │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │   ├── (CHAIN) #2\n",
       "    │       │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │       │   │       ├── (RES) Residual() #1\n",
       "    │       │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │       │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │       │   │       ├── (RES) Residual() #2\n",
       "    │       │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │       │   │       │   ├── (PAR) ...\n",
       "    │       │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │       │   │       └── (RES) Residual() #3\n",
       "    │       │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │       │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │           ├── GLU() ...\n",
       "    │       │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │       │   └── (CHAIN) #3\n",
       "    │       │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │       │       ├── Lambda(<lambda>(x))\n",
       "    │       │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │       │       ├── (PAR)\n",
       "    │       │       │   ├── Identity()\n",
       "    │       │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │       │       └── Unflatten(dim=2)\n",
       "    │       └── (SUM) ResidualBlock(in_channels=1280, out_channels=1280) #2\n",
       "    │           ├── (CHAIN)\n",
       "    │           │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │           │   ├── SiLU() #1\n",
       "    │           │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │           │   │   ├── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │           │   │   └── (CHAIN)\n",
       "    │           │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │           │   │       ├── SiLU()\n",
       "    │           │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │           │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │           │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │           │   ├── SiLU() #2\n",
       "    │           │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │           └── Identity()\n",
       "    ├── (CHAIN) UpBlocks()\n",
       "    │   ├── (CHAIN) #1\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-2)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── (RES) Residual()\n",
       "    │   │   │       │   └── UseContext(context=control, key=residuals)\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   └── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │       ├── (CHAIN)\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │   ├── SiLU() #1\n",
       "    │   │       │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │       │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       │   │   └── (CHAIN)\n",
       "    │   │       │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │       │   │       ├── SiLU()\n",
       "    │   │       │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       │   ├── SiLU() #2\n",
       "    │   │       │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #2\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-3)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   └── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │       ├── (CHAIN)\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │   ├── SiLU() #1\n",
       "    │   │       │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │       │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       │   │   └── (CHAIN)\n",
       "    │   │       │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │       │   │       ├── SiLU()\n",
       "    │   │       │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       │   ├── SiLU() #2\n",
       "    │   │       │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │       └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #3\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-4)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (CHAIN) Upsample(channels=1280)\n",
       "    │   │       ├── (PAR)\n",
       "    │   │       │   ├── Identity()\n",
       "    │   │       │   └── UseContext(context=sampling, key=shapes)\n",
       "    │   │       ├── Interpolate()\n",
       "    │   │       └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #4\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-5)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #5\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-6)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=2560, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=2560, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #6\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-7)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1920, out_channels=1280)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1920, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=1280, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1920, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(1280, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=1920, out_channels=1280, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=1280)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=1280, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=20, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=1280, num_heads=20, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=1280, num_heads=20, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=1280, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(1280,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=1280, out_features=10240, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=5120, out_features=1280, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=1280, out_features=1280, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (CHAIN) Upsample(channels=1280)\n",
       "    │   │       ├── (PAR)\n",
       "    │   │       │   ├── Identity()\n",
       "    │   │       │   └── UseContext(context=sampling, key=shapes)\n",
       "    │   │       ├── Interpolate()\n",
       "    │   │       └── Conv2d(in_channels=1280, out_channels=1280, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #7\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-8)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1920, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1920, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1920, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=1920, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #8\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-9)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=1280, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=1280, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=1280, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=1280, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #9\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-10)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=960, out_channels=640)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=960, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=640, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=960, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(640, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=960, out_channels=640, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   ├── (RES) DinoV2CrossAttention(channels=640)\n",
       "    │   │   │   ├── (CHAIN) #1\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │   │   │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │   │   │   │   └── Flatten(start_dim=2)\n",
       "    │   │   │   │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │   │   ├── Lambda(<lambda>(x))\n",
       "    │   │   │   │   └── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │   ├── (CHAIN) #2\n",
       "    │   │   │   │   └── (CHAIN) CrossAttentionBlock(embedding_dim=640, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=10, use_bias=False)\n",
       "    │   │   │   │       ├── (RES) Residual() #1\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   └── (CHAIN) SelfAttention(embedding_dim=640, num_heads=10, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       ├── (RES) Residual() #2\n",
       "    │   │   │   │       │   ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │       │   ├── (PAR) ...\n",
       "    │   │   │   │       │   └── (CHAIN) Attention(embedding_dim=640, num_heads=10, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=640, use_bias=False, is_optimized=False) ...\n",
       "    │   │   │   │       └── (RES) Residual() #3\n",
       "    │   │   │   │           ├── LayerNorm(normalized_shape=(640,), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │           ├── Linear(in_features=640, out_features=5120, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │           ├── GLU() ...\n",
       "    │   │   │   │           └── Linear(in_features=2560, out_features=640, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   └── (CHAIN) #3\n",
       "    │   │   │       ├── Linear(in_features=640, out_features=640, device=cuda:0, dtype=float32)\n",
       "    │   │   │       ├── Lambda(<lambda>(x))\n",
       "    │   │   │       ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │   │       ├── (PAR)\n",
       "    │   │   │       │   ├── Identity()\n",
       "    │   │   │       │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │   │       └── Unflatten(dim=2)\n",
       "    │   │   └── (CHAIN) Upsample(channels=640)\n",
       "    │   │       ├── (PAR)\n",
       "    │   │       │   ├── Identity()\n",
       "    │   │       │   └── UseContext(context=sampling, key=shapes)\n",
       "    │   │       ├── Interpolate()\n",
       "    │   │       └── Conv2d(in_channels=640, out_channels=640, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   ├── (CHAIN) #10\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-11)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=960, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=960, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=960, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=960, out_channels=320, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   ├── (CHAIN) #11\n",
       "    │   │   ├── (CHAIN) ResidualControlledConcatenator(n=-12)\n",
       "    │   │   │   └── (CAT)\n",
       "    │   │   │       ├── Identity()\n",
       "    │   │   │       └── (SUM)\n",
       "    │   │   │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │   │   │           └── UseContext(context=control, key=residuals) #2\n",
       "    │   │   ├── (SUM) ResidualBlock(in_channels=640, out_channels=320)\n",
       "    │   │   │   ├── (CHAIN)\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │   │   │   │   ├── SiLU() #1\n",
       "    │   │   │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │   │   │   │   │   ├── Conv2d(in_channels=640, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │   └── (CHAIN)\n",
       "    │   │   │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │   │   │   │   │       ├── SiLU()\n",
       "    │   │   │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │   │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │   │   │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │   │   │   ├── SiLU() #2\n",
       "    │   │   │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   │   └── Conv2d(in_channels=640, out_channels=320, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │   │   └── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │   │       ├── (CHAIN) #1\n",
       "    │   │       │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │   │       │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │   │       │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │   │       │   │   └── Flatten(start_dim=2)\n",
       "    │   │       │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │       │   ├── Lambda(<lambda>(x))\n",
       "    │   │       │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │       ├── (CHAIN) #2\n",
       "    │   │       │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │   │       │       ├── (RES) Residual() #1\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       ├── (RES) Residual() #2\n",
       "    │   │       │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │       │   ├── (PAR) ...\n",
       "    │   │       │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │   │       │       └── (RES) Residual() #3\n",
       "    │   │       │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │   │       │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │   │       │           ├── GLU() ...\n",
       "    │   │       │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │   │       └── (CHAIN) #3\n",
       "    │   │           ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │   │           ├── Lambda(<lambda>(x))\n",
       "    │   │           ├── Transpose(dim0=1, dim1=2)\n",
       "    │   │           ├── (PAR)\n",
       "    │   │           │   ├── Identity()\n",
       "    │   │           │   └── UseContext(context=flatten, key=sizes)\n",
       "    │   │           └── Unflatten(dim=2)\n",
       "    │   └── (CHAIN) #12\n",
       "    │       ├── (CHAIN) ResidualControlledConcatenator(n=-13)\n",
       "    │       │   └── (CAT)\n",
       "    │       │       ├── Identity()\n",
       "    │       │       └── (SUM)\n",
       "    │       │           ├── UseContext(context=unet, key=residuals) #1\n",
       "    │       │           └── UseContext(context=control, key=residuals) #2\n",
       "    │       ├── (SUM) ResidualBlock(in_channels=640, out_channels=320)\n",
       "    │       │   ├── (CHAIN)\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=640, device=cuda:0, dtype=float32) #1\n",
       "    │       │   │   ├── SiLU() #1\n",
       "    │       │   │   ├── (SUM) RangeAdapter2d(channels=320, embedding_dim=1280)\n",
       "    │       │   │   │   ├── Conv2d(in_channels=640, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   │   │   └── (CHAIN)\n",
       "    │       │   │   │       ├── UseContext(context=range_adapter, key=timestep_embedding)\n",
       "    │       │   │   │       ├── SiLU()\n",
       "    │       │   │   │       ├── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │       │   │   │       └── Reshape(shape=(320, 1, 1))\n",
       "    │       │   │   ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32) #2\n",
       "    │       │   │   ├── SiLU() #2\n",
       "    │       │   │   └── Conv2d(in_channels=320, out_channels=320, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       │   └── Conv2d(in_channels=640, out_channels=320, kernel_size=(1, 1), device=cuda:0, dtype=float32)\n",
       "    │       └── (RES) DinoV2CrossAttention(channels=320)\n",
       "    │           ├── (CHAIN) #1\n",
       "    │           │   ├── GroupNorm(num_groups=32, eps=1e-06, channels=320, device=cuda:0, dtype=float32)\n",
       "    │           │   ├── (CHAIN) StatefulFlatten(start_dim=2)\n",
       "    │           │   │   ├── SetContext(context=flatten, key=sizes)\n",
       "    │           │   │   └── Flatten(start_dim=2)\n",
       "    │           │   ├── Transpose(dim0=1, dim1=2)\n",
       "    │           │   ├── Lambda(<lambda>(x))\n",
       "    │           │   └── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │           ├── (CHAIN) #2\n",
       "    │           │   └── (CHAIN) CrossAttentionBlock(embedding_dim=320, context_embedding_dim=1024, context_key=dinov2_object_embedding, num_heads=5, use_bias=False)\n",
       "    │           │       ├── (RES) Residual() #1\n",
       "    │           │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │           │       │   └── (CHAIN) SelfAttention(embedding_dim=320, num_heads=5, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │           │       ├── (RES) Residual() #2\n",
       "    │           │       │   ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │           │       │   ├── (PAR) ...\n",
       "    │           │       │   └── (CHAIN) Attention(embedding_dim=320, num_heads=5, key_embedding_dim=1024, value_embedding_dim=1024, inner_dim=320, use_bias=False, is_optimized=False) ...\n",
       "    │           │       └── (RES) Residual() #3\n",
       "    │           │           ├── LayerNorm(normalized_shape=(320,), device=cuda:0, dtype=float32)\n",
       "    │           │           ├── Linear(in_features=320, out_features=2560, device=cuda:0, dtype=float32) #1\n",
       "    │           │           ├── GLU() ...\n",
       "    │           │           └── Linear(in_features=1280, out_features=320, device=cuda:0, dtype=float32) #2\n",
       "    │           └── (CHAIN) #3\n",
       "    │               ├── Linear(in_features=320, out_features=320, device=cuda:0, dtype=float32)\n",
       "    │               ├── Lambda(<lambda>(x))\n",
       "    │               ├── Transpose(dim0=1, dim1=2)\n",
       "    │               ├── (PAR)\n",
       "    │               │   ├── Identity()\n",
       "    │               │   └── UseContext(context=flatten, key=sizes)\n",
       "    │               └── Unflatten(dim=2)\n",
       "    └── (CHAIN)\n",
       "        ├── GroupNorm(num_groups=32, channels=320, device=cuda:0, dtype=float32)\n",
       "        ├── SiLU()\n",
       "        └── Conv2d(in_channels=320, out_channels=4, kernel_size=(3, 3), padding=(1, 1), device=cuda:0, dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
